{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\python\\Anaconda3\\envs\\tensorFLow-gpu\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "F:\\python\\Anaconda3\\envs\\tensorFLow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\python\\Anaconda3\\envs\\tensorFLow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\python\\Anaconda3\\envs\\tensorFLow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\python\\Anaconda3\\envs\\tensorFLow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\python\\Anaconda3\\envs\\tensorFLow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\python\\Anaconda3\\envs\\tensorFLow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# 导入所需模块\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取CIFAR-10数据\n",
    "(x_train_img, y_train_label),(x_test_img, y_test_label) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_img.shape:  (50000, 32, 32, 3)  y_train_label.shape:  (50000, 1)\n",
      "x_test_img.shape:  (10000, 32, 32, 3)  y_test_label.shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 显示训练和验证数据的shape\n",
    "print('x_train_img.shape: ', x_train_img.shape, ' y_train_label.shape: ', y_train_label.shape)\n",
    "print('x_test_img.shape: ', x_test_img.shape, ' y_test_label.shape: ', y_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将features（照片的特征值）标准化\n",
    "# 标准化可以提高预测精度，并且可以更快收敛\n",
    "x_train_img_normalize = x_train_img.astype('float32') / 255.0\n",
    "x_test_img_normalize = x_test_img.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label以一位有效编码进行转换\n",
    "from keras.utils import np_utils\n",
    "y_train_label_OneHot = np_utils.to_categorical(y_train_label)\n",
    "y_test_label_OneHot = np_utils.to_categorical(y_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.导入所需模块\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立卷积层1与池化层1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立卷积层1\n",
    "model.add(Conv2D(filters=32,\n",
    "                                kernel_size=(3, 3),\n",
    "                                input_shape=(32, 32, 3),\n",
    "                                activation='relu',\n",
    "                                padding='same'))\n",
    "# 加入DropOut，避免过度拟合\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "# 【新增加Conv2D 层】\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# 建立池化层1，执行缩减采样\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立卷积层2与池化层2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立卷积层2\n",
    "model.add(Conv2D(filters=64,\n",
    "                                kernel_size=(3, 3),\n",
    "                                activation='relu',\n",
    "                                padding='same'))\n",
    "# 加入DropOut，避免过度拟合\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "# 【新增加Conv2D 层】\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# 建立池化层2，执行缩减采样\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立卷积层3和池化层3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立卷积层3\n",
    "model.add(Conv2D(filters=128,\n",
    "                                kernel_size=(3, 3),\n",
    "                                activation='relu',\n",
    "                                padding='same'))\n",
    "# 加入DropOut，避免过度拟合\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "# 【新增加Conv2D 层】\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# 建立池化层3，执行缩减采样\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立神经网络层（平坦层，隐藏层1，隐藏层2，输出层）\n",
    "\n",
    "**我们建立更宽，更深的神经网络， 加入隐藏层1（2500个神经元）和隐藏层2（1500个神经元）。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平坦层\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "# 隐藏层1\n",
    "model.add(Dense(2500, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# 隐藏层2\n",
    "model.add(Dense(1500, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# 输出层\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型\n",
    "\n",
    "#### 为了增加准确率,执行50个训练周期，这需要花很长时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 81s 2ms/step - loss: 1.8643 - acc: 0.3034 - val_loss: 1.7372 - val_acc: 0.3697\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 1.4255 - acc: 0.4737 - val_loss: 1.2955 - val_acc: 0.5322\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 1.2249 - acc: 0.5573 - val_loss: 1.1833 - val_acc: 0.5662\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 1.0878 - acc: 0.6105 - val_loss: 1.0088 - val_acc: 0.6537\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 0.9942 - acc: 0.6447 - val_loss: 0.9049 - val_acc: 0.6817\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 0.8949 - acc: 0.6807 - val_loss: 0.8829 - val_acc: 0.6949\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 0.8296 - acc: 0.7029 - val_loss: 0.8450 - val_acc: 0.7029\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 0.7593 - acc: 0.7298 - val_loss: 0.7923 - val_acc: 0.7272\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 0.7122 - acc: 0.7485 - val_loss: 0.7516 - val_acc: 0.7392\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 0.6539 - acc: 0.7700 - val_loss: 0.7051 - val_acc: 0.7525\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 0.6165 - acc: 0.7815 - val_loss: 0.6922 - val_acc: 0.7627\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 69s 2ms/step - loss: 0.5627 - acc: 0.8002 - val_loss: 0.6559 - val_acc: 0.7737\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 70s 2ms/step - loss: 0.5300 - acc: 0.8109 - val_loss: 0.6626 - val_acc: 0.7754\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 161s 4ms/step - loss: 0.5040 - acc: 0.8208 - val_loss: 0.6610 - val_acc: 0.7826\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 274s 7ms/step - loss: 0.4670 - acc: 0.8353 - val_loss: 0.6505 - val_acc: 0.7872\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 275s 7ms/step - loss: 0.4338 - acc: 0.8437 - val_loss: 0.6358 - val_acc: 0.7901\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 274s 7ms/step - loss: 0.4068 - acc: 0.8547 - val_loss: 0.6655 - val_acc: 0.7768\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 273s 7ms/step - loss: 0.3786 - acc: 0.8655 - val_loss: 0.6585 - val_acc: 0.7898\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 272s 7ms/step - loss: 0.3609 - acc: 0.8692 - val_loss: 0.6653 - val_acc: 0.7857\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 274s 7ms/step - loss: 0.3259 - acc: 0.8849 - val_loss: 0.6910 - val_acc: 0.7913\n",
      "Epoch 21/50\n",
      "36300/40000 [==========================>...] - ETA: 24s - loss: 0.3091 - acc: 0.8903"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x_train_img_normalize, y_train_label_OneHot, validation_split=0.2, epochs=50, batch_size=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立show_train_history显示训练过程\n",
    "# 可以使用如下方法，读取train_history，以图表显示训练过程。\n",
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history, train, validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Train')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_train_history(train_history, 'acc', 'val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test_img_normalize, y_test_label_OneHot, verbose=0)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.10模型的保存与加载\n",
    "\n",
    "### 上面程序的训练必须花费很长时间，往往需要数小时。有时还可能因为某些原因导致计算机宕机，这样之前的训练就前功尽弃了，解决的方法是：每次程序执行完成训练后，将模型权重保存一下。下次程序执行训练之前，先加载模型权重，在继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.设置训练周期\n",
    "# 每次训练的周期不要太多，下面设置为5\n",
    "train_history = model.fit(x_train_img_normalize, y_train_label_OneHot, validation_split=0.2, epochs=5, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.在执行训练之前加载模型权重\n",
    "try:\n",
    "    model.load_weights(\"saveModel/cifarCnnModel.h5\")\n",
    "    print('模型加载成功！继续训练模型')\n",
    "except:\n",
    "    print('加载模型失败！开始训练一个模型')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从以上执行结果可知，因为第一次执行尚未保存模型权重，所以会显示“加载模型失败！开始训练一个模型”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在程序的最后保存模型权重\n",
    "# 将这次执行5个训练周期的结果使用model.save_weights保存在文件中。\n",
    "model.save_weights('saveModel/cifarCnnModel.h5')\n",
    "print('save Model to dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二次执行程序\n",
    "# 第二次执行之前，同样先试用 model.load_weights 加载模型权重\n",
    "try:\n",
    "    model.load_weights('saveModel/cifarCnnModel.h5')\n",
    "    print('模型加载成功！继续训练模型')\n",
    "except:\n",
    "    print('加载模型失败，开始训练一个新模型')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从以上执行结果可知，因为第二次执行会加载之前保存的模型权重，所以会显示“模型加载成功！继续训练模型”，这样就可以接着第一次训练的结果继续训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.11 结论\n",
    "\n",
    "### 在本章节中，我们介绍了使用keras建立卷积神经网络识别 CIFAR-10图像数据。后续章节我们将以 _<u>多层感知器模型</u>_ 来预测泰坦尼克号乘客的生存率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tf-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
